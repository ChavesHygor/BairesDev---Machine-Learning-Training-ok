{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNJY+NMH5bseNbhlN2aMoQk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChavesHygor/BairesDev---Machine-Learning-Training-ok/blob/main/objetos_similares.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qraHxEmvjiX",
        "outputId": "b0d071ca-d1f4-4920-9c51-2a3b7fe0ef26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Line magic function `%%writefile` not found.\n"
          ]
        }
      ],
      "source": [
        "#hide\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#hide\n",
        "%%writefile kaggle.json\n",
        "{\"username\":\"<your kaggle username>\",\"key\":\"<your kaggle api key>\"}\n",
        "#hide\n",
        "!pip install -q -U kaggle\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "#hide-output\n",
        "# downloading raw images from kaggle\n",
        "!kaggle datasets download -d paramaggarwal/fashion-product-images-small\n",
        "!unzip fashion-product-images-small.zip\n",
        "\n",
        "import pandas as pd\n",
        "from shutil import move\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Criar e organizar diretórios\n",
        "os.mkdir('/content/Fashion_data')\n",
        "os.chdir('/content/Fashion_data')\n",
        "\n",
        "df = pd.read_csv('/content/styles.csv', usecols=['id','masterCategory']).reset_index()\n",
        "df['id'] = df['id'].astype('str')\n",
        "\n",
        "all_images = os.listdir('/content/images/')\n",
        "co = 0\n",
        "os.mkdir('/content/Fashion_data/categories')\n",
        "for image in tqdm(all_images):\n",
        "    category = df[df['id'] == image.split('.')[0]]['masterCategory']\n",
        "    category = str(list(category)[0])\n",
        "    if not os.path.exists(os.path.join('/content/Fashion_data/categories', category)):\n",
        "        os.mkdir(os.path.join('/content/Fashion_data/categories', category))\n",
        "    path_from = os.path.join('/content/images', image)\n",
        "    path_to = os.path.join('/content/Fashion_data/categories', category, image)\n",
        "    move(path_from, path_to)\n",
        "    co += 1\n",
        "print('Moved {} images.'.format(co))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C4CC52dywHQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
        "\n",
        "MODULE_HANDLE = 'https://tfhub.dev/google/bit/m-r50x3/1'\n",
        "IMAGE_SIZE = (224, 224)\n",
        "print(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))\n",
        "BATCH_SIZE = 32\n",
        "N_FEATURES = 256\n",
        "\n",
        "# Preparação dos geradores de dados\n",
        "data_dir = '/content/Fashion_data/categories'\n",
        "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
        "dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n",
        "                       interpolation=\"bilinear\")\n",
        "\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    **datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)\n",
        "\n",
        "do_data_augmentation = False\n",
        "if do_data_augmentation:\n",
        "  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      rotation_range=40,\n",
        "      horizontal_flip=True,\n",
        "      width_shift_range=0.2, height_shift_range=0.2,\n",
        "      shear_range=0.2, zoom_range=0.2,\n",
        "      **datagen_kwargs)\n",
        "else:\n",
        "  train_datagen = valid_datagen\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs)\n",
        "\n",
        "# Construção do modelo de Deep Learning\n",
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
        "    hub.KerasLayer(MODULE_HANDLE, trainable=False),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(N_FEATURES,\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(train_generator.num_classes,\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
        "])\n",
        "model.build((None,)+IMAGE_SIZE+(3,))\n",
        "model.summary()\n",
        "\n",
        "# Compilação e Treinamento do modelo\n",
        "lr = 0.003 * BATCH_SIZE / 512\n",
        "SCHEDULE_LENGTH = 500\n",
        "SCHEDULE_BOUNDARIES = [200, 300, 400]\n",
        "lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=SCHEDULE_BOUNDARIES,\n",
        "                                                                   values=[lr, lr*0.1, lr*0.001, lr*0.0001])\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])\n",
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
        "hist = model.fit(\n",
        "    train_generator,\n",
        "    epochs=5, steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=validation_steps).history\n",
        "\n",
        "# Salvar o extrator de características\n",
        "if not os.path.exists('/content/drive/MyDrive/ImgSim/'):\n",
        "    os.mkdir('/content/drive/MyDrive/ImgSim/')\n",
        "\n",
        "feature_extractor = tf.keras.Model(inputs=model.inputs, outputs=model.layers[-3].output)\n",
        "feature_extractor.save('/content/drive/MyDrive/ImgSim/bit_feature_extractor', save_format='tf')\n",
        "\n",
        "saved_model_path = '/content/drive/MyDrive/ImgSim/bit_model'\n",
        "tf.saved_model.save(model, saved_model_path)"
      ],
      "metadata": {
        "id": "Vqy3horIv0Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "img_paths = []\n",
        "for path in Path('/content/Fashion_data/categories').rglob('*.jpg'):\n",
        "  img_paths.append(path)\n",
        "np.random.shuffle(img_paths)\n",
        "\n",
        "def load_img(path):\n",
        "  img = tf.io.read_file(path)\n",
        "  img = tf.io.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.resize_with_pad(img, 224, 224)\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "  return img\n",
        "\n",
        "TRANSFER_LEARNING_FLAG = 1\n",
        "if TRANSFER_LEARNING_FLAG:\n",
        "  module = tf.keras.models.load_model('/content/drive/MyDrive/ImgSim/bit_feature_extractor')\n",
        "else:\n",
        "  module_handle = \"https://tfhub.dev/google/bit/s-r50x3/ilsvrc2012_classification/1\"\n",
        "  module = hub.load(module_handle)\n",
        "\n",
        "imgvec_path = '/content/img_vectors/'\n",
        "Path(imgvec_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for filename in tqdm(img_paths[:5000]):\n",
        "    img = load_img(str(filename))\n",
        "    features = module(img)\n",
        "    feature_set = np.squeeze(features)\n",
        "    outfile_name = os.path.basename(filename).split('.')[0] + \".npz\"\n",
        "    out_path_file = os.path.join(imgvec_path, outfile_name)\n",
        "    np.savetxt(out_path_file, feature_set, delimiter=',')"
      ],
      "metadata": {
        "id": "_pcOCgMJv7Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "!pip install -q annoy\n",
        "import json\n",
        "from annoy import AnnoyIndex\n",
        "from scipy import spatial\n",
        "import pickle\n",
        "from IPython.display import Image as dispImage\n",
        "from IPython.display import display\n",
        "\n",
        "# O 'styles.csv' precisa estar acessível, então ajuste o caminho se necessário.\n",
        "# Exemplo: root_path = '/content/'\n",
        "# styles = pd.read_csv(root_path+'styles.csv', error_bad_lines=False)\n",
        "# styles['id'] = styles['id'].astype('str')\n",
        "# styles.to_csv(root_path+'styles.csv', index=False)\n",
        "# def match_id(fname):\n",
        "#   return styles.index[styles.id==fname].values[0]\n",
        "\n",
        "# Definir estruturas de dados\n",
        "file_index_to_file_name = {}\n",
        "file_index_to_file_vector = {}\n",
        "file_index_to_product_id = {}\n",
        "\n",
        "# Configurar Annoy\n",
        "dims = 256\n",
        "n_nearest_neighbors = 20\n",
        "trees = 10000\n",
        "\n",
        "# Ler todos os arquivos de vetores\n",
        "allfiles = glob.glob('/content/img_vectors/*.npz')\n",
        "\n",
        "# Criar e popular o índice Annoy\n",
        "t = AnnoyIndex(dims, metric='angular')\n",
        "for findex, fname in tqdm(enumerate(allfiles)):\n",
        "    file_vector = np.loadtxt(fname)\n",
        "    file_name = os.path.basename(fname).split('.')[0]\n",
        "    file_index_to_file_name[findex] = file_name\n",
        "    file_index_to_file_vector[findex] = file_vector\n",
        "    t.add_item(findex, file_vector)\n",
        "\n",
        "# Salvar o índice Annoy\n",
        "annoy_model_path = '/content/drive/MyDrive/ImgSim/fashion_annoy.ann'\n",
        "t.build(trees)\n",
        "t.save(annoy_model_path)\n",
        "\n",
        "# Salvar os metadados\n",
        "with open('/content/drive/MyDrive/ImgSim/file_index_to_file_name.json', 'w') as f:\n",
        "    json.dump(file_index_to_file_name, f)\n",
        "\n",
        "with open('/content/drive/MyDrive/ImgSim/file_index_to_product_id.json', 'w') as f:\n",
        "    json.dump(file_index_to_product_id, f)\n",
        "\n",
        "# Carregar o modelo, o índice e os metadados\n",
        "def load_recommendation_system(model_path, annoy_path, metadata_path):\n",
        "    print(\"Loading feature extractor model...\")\n",
        "    extractor = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    print(\"Loading Annoy index...\")\n",
        "    dims = extractor.output_shape[1]\n",
        "    annoy_index = AnnoyIndex(dims, 'angular')\n",
        "    annoy_index.load(annoy_path)\n",
        "\n",
        "    with open(metadata_path + 'file_index_to_file_name.json', 'r') as f:\n",
        "        file_index_to_file_name = json.load(f)\n",
        "\n",
        "    return extractor, annoy_index, file_index_to_file_name\n",
        "\n",
        "# Função para encontrar e exibir imagens similares\n",
        "def find_similar_images(image_path, extractor, annoy_index, file_index_to_file_name, n_results=5):\n",
        "    print(f\"Finding similar images for: {image_path}\")\n",
        "\n",
        "    # 1. Carregar e pré-processar a imagem de busca\n",
        "    img = load_img(image_path)\n",
        "\n",
        "    # 2. Extrair o vetor de características da imagem de busca\n",
        "    search_vector = np.squeeze(extractor(img))\n",
        "\n",
        "    # 3. Encontrar os vizinhos mais próximos no índice Annoy\n",
        "    nearest_neighbors_ids = annoy_index.get_nns_by_vector(search_vector, n=n_results, search_k=-1)\n",
        "\n",
        "    # Exibir a imagem de busca\n",
        "    print(\"\\n--- Imagem de Busca ---\")\n",
        "    display(dispImage(filename=image_path, width=200))\n",
        "\n",
        "    # Exibir as imagens recomendadas\n",
        "    print(\"\\n--- Imagens Recomendadas ---\")\n",
        "\n",
        "    for neighbor_id in nearest_neighbors_ids:\n",
        "        # Pular a própria imagem de busca\n",
        "        if file_index_to_file_name[str(neighbor_id)] == os.path.basename(image_path).split('.')[0]:\n",
        "            continue\n",
        "\n",
        "        recommended_img_id = file_index_to_file_name[str(neighbor_id)]\n",
        "        recommended_img_path = glob.glob(f'/content/Fashion_data/categories/**/{recommended_img_id}.jpg', recursive=True)[0]\n",
        "\n",
        "        display(dispImage(filename=recommended_img_path, width=200))\n",
        "        print(f\"ID do produto: {recommended_img_id}\")\n",
        "\n",
        "# --- Exemplo de Uso do Sistema ---\n",
        "# Caminhos salvos na seção 2\n",
        "model_path = '/content/drive/MyDrive/ImgSim/bit_feature_extractor'\n",
        "annoy_path = '/content/drive/MyDrive/ImgSim/fashion_annoy.ann'\n",
        "metadata_path = '/content/drive/MyDrive/ImgSim/'\n",
        "\n",
        "# Carregar o sistema de recomendação\n",
        "feature_extractor, annoy_index, file_index_to_file_name = load_recommendation_system(model_path, annoy_path, metadata_path)\n",
        "\n",
        "# Caminho para uma imagem de teste (substitua pelo seu próprio)\n",
        "test_img = '/content/Fashion_data/categories/Accessories/1941.jpg'\n",
        "\n",
        "# Encontrar e exibir as recomendações\n",
        "find_similar_images(test_img, feature_extractor, annoy_index, file_index_to_file_name, n_results=5)"
      ],
      "metadata": {
        "id": "l_5-Jp2Yv-QH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}