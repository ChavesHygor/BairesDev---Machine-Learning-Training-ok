{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPAeLu18yC8aplVYxSoARYH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChavesHygor/BairesDev---Machine-Learning-Training-ok/blob/main/Cria%C3%A7%C3%A3o_de_Uma_Base_de_Dados_e_Treinamento_da_Rede_YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AzLWLHYhIotj",
        "outputId": "cfc7a618-12c2-4810-a86f-a5576427733e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Aug 26 16:37:25 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# 1. Verifica se a GPU está ativa e alocada para o notebook\n",
        "!nvidia-smi\n",
        "\n",
        "# 2. Monta o Google Drive para armazenamento persistente\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# 3. Cria um link simbólico para a pasta darknet no seu Drive.\n",
        "#    Isso evita erros com espaços no nome \"My Drive\".\n",
        "#    Certifique-se de que a pasta 'darknet' existe na raiz do seu Drive.\n",
        "!ln -s \"/content/gdrive/My Drive/darknet\" /mydrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ETAPA 2: Clonar e Compilar o Darknet ---\n",
        "import os\n",
        "\n",
        "# 1. Clona o repositório do darknet, se ainda não foi clonado\n",
        "if not os.path.exists('darknet'):\n",
        "    print(\"Clonando o repositório do Darknet...\")\n",
        "    !git clone https://github.com/kriyeng/darknet/\n",
        "else:\n",
        "    print(\"Repositório Darknet já existe.\")\n",
        "\n",
        "# 2. Entra na pasta do darknet para poder executar os comandos\n",
        "%cd /content/darknet\n",
        "\n",
        "# 3. Edita o Makefile para habilitar GPU, CUDNN e OPENCV\n",
        "print(\"\\nConfigurando o Makefile...\")\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=1/CUDNN_HALF=0/' Makefile # Correção de compatibilidade com cuDNN do Colab\n",
        "\n",
        "# 4. Instala a biblioteca de desenvolvimento do OpenCV\n",
        "print(\"\\nInstalando dependências do OpenCV...\")\n",
        "!apt-get -y install libopencv-dev\n",
        "\n",
        "# 5. Cria o link simbólico para compatibilidade da versão do OpenCV\n",
        "print(\"\\nCriando link simbólico do OpenCV...\")\n",
        "!ln -sf /usr/lib/x86_64-linux-gnu/pkgconfig/opencv4.pc /usr/lib/x86_64-linux-gnu/pkgconfig/opencv.pc\n",
        "\n",
        "# 6. Compila o darknet\n",
        "print(\"\\nCompilando o Darknet... (Isso pode levar alguns minutos)\")\n",
        "!make clean  # Limpa compilações anteriores\n",
        "!make       # Compila o código\n",
        "\n",
        "print(\"\\nCompilação do Darknet concluída!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oGU-q19eI7Nz",
        "outputId": "2f0e1186-e67e-4bd3-f91f-9902a202270f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clonando o repositório do Darknet...\n",
            "Cloning into 'darknet'...\n",
            "remote: Enumerating objects: 10068, done.\u001b[K\n",
            "remote: Total 10068 (delta 0), reused 0 (delta 0), pack-reused 10068 (from 1)\u001b[K\n",
            "Receiving objects: 100% (10068/10068), 10.14 MiB | 16.33 MiB/s, done.\n",
            "Resolving deltas: 100% (6715/6715), done.\n",
            "/content/darknet\n",
            "\n",
            "Configurando o Makefile...\n",
            "\n",
            "Instalando dependências do OpenCV...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libopencv-dev is already the newest version (4.5.4+dfsg-9ubuntu4+jammy1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "\n",
            "Criando link simbólico do OpenCV...\n",
            "\n",
            "Compilando o Darknet... (Isso pode levar alguns minutos)\n",
            "rm -rf ./obj/image_opencv.o ./obj/http_stream.o ./obj/gemm.o ./obj/utils.o ./obj/dark_cuda.o ./obj/convolutional_layer.o ./obj/list.o ./obj/image.o ./obj/activations.o ./obj/im2col.o ./obj/col2im.o ./obj/blas.o ./obj/crop_layer.o ./obj/dropout_layer.o ./obj/maxpool_layer.o ./obj/softmax_layer.o ./obj/data.o ./obj/matrix.o ./obj/network.o ./obj/connected_layer.o ./obj/cost_layer.o ./obj/parser.o ./obj/option_list.o ./obj/darknet.o ./obj/detection_layer.o ./obj/captcha.o ./obj/route_layer.o ./obj/writing.o ./obj/box.o ./obj/nightmare.o ./obj/normalization_layer.o ./obj/avgpool_layer.o ./obj/coco.o ./obj/dice.o ./obj/yolo.o ./obj/detector.o ./obj/layer.o ./obj/compare.o ./obj/classifier.o ./obj/local_layer.o ./obj/swag.o ./obj/shortcut_layer.o ./obj/activation_layer.o ./obj/rnn_layer.o ./obj/gru_layer.o ./obj/rnn.o ./obj/rnn_vid.o ./obj/crnn_layer.o ./obj/demo.o ./obj/tag.o ./obj/cifar.o ./obj/go.o ./obj/batchnorm_layer.o ./obj/art.o ./obj/region_layer.o ./obj/reorg_layer.o ./obj/reorg_old_layer.o ./obj/super.o ./obj/voxel.o ./obj/tree.o ./obj/yolo_layer.o ./obj/upsample_layer.o ./obj/lstm_layer.o ./obj/convolutional_kernels.o ./obj/activation_kernels.o ./obj/im2col_kernels.o ./obj/col2im_kernels.o ./obj/blas_kernels.o ./obj/crop_layer_kernels.o ./obj/dropout_layer_kernels.o ./obj/maxpool_layer_kernels.o ./obj/network_kernels.o ./obj/avgpool_layer_kernels.o darknet  \n",
            "chmod +x *.sh\n",
            "g++ -std=c++11 -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -c ./src/image_opencv.cpp -o obj/image_opencv.o\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid draw_detections_cv_v3(mat_cv*, detection*, int, float, char**, image**, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:896:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Krgb\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-but-set-variable\u0007-Wunused-but-set-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  896 |                 float \u001b[01;35m\u001b[Krgb\u001b[m\u001b[K[3];\n",
            "      |                       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "g++ -std=c++11 -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -c ./src/http_stream.cpp -o obj/http_stream.o\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kbool JSON_sender::write(const char*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:228:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  228 |                 int \u001b[01;35m\u001b[Kn\u001b[m\u001b[K = _write(client, outputbuf, outlen);\n",
            "      |                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kbool MJPG_sender::write(const cv::Mat&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:475:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  475 |                 if (\u001b[01;35m\u001b[Kn < outlen\u001b[m\u001b[K)\n",
            "      |                     \u001b[01;35m\u001b[K~~^~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -c ./src/gemm.c -o obj/gemm.o\n",
            "\u001b[01m\u001b[K./src/gemm.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kconvolution_2d\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/gemm.c:2016:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kout_w\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            " 2016 |     const int \u001b[01;35m\u001b[Kout_w\u001b[m\u001b[K = (w + 2 * pad - ksize) / stride + 1;    // output_width=input_width for stride=1 and pad=1\n",
            "      |               \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/gemm.c:2015:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kout_h\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            " 2015 |     const int \u001b[01;35m\u001b[Kout_h\u001b[m\u001b[K = (h + 2 * pad - ksize) / stride + 1;    // output_height=input_height for stride=1 and pad=1\n",
            "      |               \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -c ./src/utils.c -o obj/utils.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -c ./src/dark_cuda.c -o obj/dark_cuda.o\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kget_cuda_stream\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:120:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kbuffer\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  120 |             char \u001b[01;35m\u001b[Kbuffer\u001b[m\u001b[K[256];\n",
            "      |                  \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kget_cuda_memcpy_stream\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:141:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kbuffer\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  141 |             char \u001b[01;35m\u001b[Kbuffer\u001b[m\u001b[K[256];\n",
            "      |                  \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcudnn_handle\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:161:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kstatus\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  161 |         cudnnStatus_t \u001b[01;35m\u001b[Kstatus\u001b[m\u001b[K = cudnnSetStream(handle[i], get_cuda_stream());\n",
            "      |                       \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -c ./src/convolutional_layer.c -o obj/convolutional_layer.o\n",
            "\u001b[01m\u001b[K./src/convolutional_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcudnn_convolutional_setup\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/convolutional_layer.c:277:24:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[K‘\u001b[01m\u001b[KCUDNN_CONVOLUTION_FWD_PREFER_FASTEST\u001b[m\u001b[K’ undeclared (first use in this function); did you mean ‘\u001b[01m\u001b[KCUDNN_CONVOLUTION_BWD_FILTER_ALGO_3\u001b[m\u001b[K’?\n",
            "  277 |     int forward_algo = \u001b[01;31m\u001b[KCUDNN_CONVOLUTION_FWD_PREFER_FASTEST\u001b[m\u001b[K;\n",
            "      |                        \u001b[01;31m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "      |                        \u001b[32m\u001b[KCUDNN_CONVOLUTION_BWD_FILTER_ALGO_3\u001b[m\u001b[K\n",
            "compilation terminated due to -Wfatal-errors.\n",
            "make: *** [Makefile:146: obj/convolutional_layer.o] Error 1\n",
            "\n",
            "Compilação do Darknet concluída!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ETAPA 3: Preparação do Dataset ---\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# 1. Baixar o dataset de detecção de máscaras para a pasta /mydrive\n",
        "dataset_path = \"/mydrive/Face-Mask-Detection\"\n",
        "if not os.path.exists(dataset_path):\n",
        "    print(f\"Dataset não encontrado. Clonando para '{dataset_path}'...\")\n",
        "    !git clone https://github.com/datoun/Face-Mask-Detection.git {dataset_path}\n",
        "else:\n",
        "    print(\"Pasta do dataset já existe.\")\n",
        "\n",
        "# 2. Criar o arquivo obj.names com as nossas classes\n",
        "#    (Usando %%writefile, que deve estar na PRIMEIRA linha da célula)\n",
        "print(\"\\nCriando arquivo obj.names...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AcBYepkGJA5k",
        "outputId": "2562d2d9-fffc-414e-8b3a-c3ed92d5a76b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset não encontrado. Clonando para '/mydrive/Face-Mask-Detection'...\n",
            "Cloning into '/mydrive/Face-Mask-Detection'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n",
            "\n",
            "Criando arquivo obj.names...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /mydrive/obj.names\n",
        "with_mask\n",
        "without_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cXnTVEZKfEU",
        "outputId": "fb1161ad-a237-4dad-9bcc-30697d407d98"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /mydrive/obj.names\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /mydrive/obj.data\n",
        "classes = 2\n",
        "train = /mydrive/train.txt\n",
        "valid = /mydrive/test.txt\n",
        "names = /mydrive/obj.names\n",
        "backup = /mydrive/backup/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jyj3J-7KKjC8",
        "outputId": "fec54437-8434-4874-f18f-d5ce97f6a721"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /mydrive/obj.data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /mydrive/obj.names\n",
        "with_mask\n",
        "without_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF0kRBMfKnL7",
        "outputId": "1bab6226-2c3b-42a1-d4d2-500b5daf26bc"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /mydrive/obj.names\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /mydrive/obj.data\n",
        "classes = 2\n",
        "train = mydrive/train.txt\n",
        "valid = mydrive/test.txt\n",
        "names = mydrive/obj.names\n",
        "backup = mydrive/backup"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQPPQqs4KpYj",
        "outputId": "0cdd82d1-83ed-48d0-9337-d13407f0a4fa"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /mydrive/obj.data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ETAPA 3: Preparação do Dataset (VERSÃO FINAL COM VERIFICAÇÃO DE DOWNLOAD) ---\n",
        "import os\n",
        "import glob\n",
        "\n",
        "print(\"--- Iniciando a Etapa 3: Preparação Completa do Dataset ---\")\n",
        "\n",
        "# --- 1. Definir caminhos e limpar dados antigos ---\n",
        "dataset_dir = \"/mydrive/FaceMaskDataset\"\n",
        "zip_file = \"/content/dataset.zip\"\n",
        "\n",
        "if os.path.exists(dataset_dir):\n",
        "    print(f\"Removendo a pasta do dataset antigo: {dataset_dir}\")\n",
        "    !rm -rf {dataset_dir}\n",
        "\n",
        "# --- 2. Baixar o Dataset com um novo link e com barra de progresso ---\n",
        "print(f\"\\nBaixando o novo dataset como '{os.path.basename(zip_file)}'...\")\n",
        "# Este é um novo link, mais estável, para um dataset similar do Roboflow.\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1_2aIBSf9Jm8h8g7e1e40w5f2s4OK29N5' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1_2aIBSf9Jm8h8g7e1e40w5f2s4OK29N5\" -O {zip_file} && rm -rf /tmp/cookies.txt\n",
        "\n",
        "# --- 3. VERIFICAR se o download foi bem-sucedido ---\n",
        "print(\"\\nVerificando o tipo do arquivo baixado...\")\n",
        "# Este comando deve retornar \"Zip archive data\". Se retornar \"HTML document\" ou outra coisa, o download falhou.\n",
        "!file {zip_file}\n",
        "\n",
        "# --- 4. Descompactar o Dataset ---\n",
        "print(f\"\\nDescompactando o dataset para '{dataset_dir}'...\")\n",
        "# Usamos '&&' para executar o próximo comando apenas se o anterior for bem-sucedido\n",
        "!unzip -q -o {zip_file} -d {dataset_dir} && echo \"Dataset descompactado com sucesso!\"\n",
        "\n",
        "# --- 5. VERIFICAR se a descompactação funcionou ---\n",
        "# Verificamos se um arquivo essencial existe antes de continuar\n",
        "check_file = os.path.join(dataset_dir, \"train/_darknet.txt\")\n",
        "if not os.path.exists(check_file):\n",
        "    print(\"\\nERRO CRÍTICO: A descompactação falhou ou o dataset não contém os arquivos esperados.\")\n",
        "    print(f\"O arquivo '{check_file}' não foi encontrado.\")\n",
        "else:\n",
        "    # --- 6. Criar o Arquivo obj.data ---\n",
        "    print(\"\\nCriando o arquivo de configuração obj.data...\")\n",
        "    with open(\"/mydrive/obj.data\", \"w\") as f:\n",
        "        f.write(\"classes = 2\\n\")\n",
        "        f.write(f\"train = {dataset_dir}/train/_darknet.txt\\n\")\n",
        "        f.write(f\"valid = {dataset_dir}/valid/_darknet.txt\\n\")\n",
        "        f.write(f\"names = {dataset_dir}/_darknet.labels\\n\")\n",
        "        f.write(\"backup = /mydrive/backup/\\n\")\n",
        "\n",
        "    # --- 7. Criar a Pasta de Backup ---\n",
        "    !mkdir -p /mydrive/backup\n",
        "\n",
        "    print(\"\\n--- PASSO 3 CONCLUÍDO COM SUCESSO! ---\")\n",
        "    print(\"Todos os arquivos de configuração e listas de imagens foram criados a partir do novo dataset.\")\n",
        "    train_count = len(open(f\"{dataset_dir}/train/_darknet.txt\").readlines())\n",
        "    valid_count = len(open(f\"{dataset_dir}/valid/_darknet.txt\").readlines())\n",
        "    print(f\"Imagens de treino: {train_count}\")\n",
        "    print(f\"Imagens de validação/teste: {valid_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iovk3YJJJE8j",
        "outputId": "0f58c205-655b-432f-de78-8726d3ebb818"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Iniciando a Etapa 3: Preparação Completa do Dataset ---\n",
            "\n",
            "Baixando o novo dataset como 'dataset.zip'...\n",
            "--2025-08-26 16:37:55--  https://docs.google.com/uc?export=download&confirm=&id=1_2aIBSf9Jm8h8g7e1e40w5f2s4OK29N5\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.127.139, 108.177.127.138, 108.177.127.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.127.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1_2aIBSf9Jm8h8g7e1e40w5f2s4OK29N5&export=download [following]\n",
            "--2025-08-26 16:37:55--  https://drive.usercontent.google.com/download?id=1_2aIBSf9Jm8h8g7e1e40w5f2s4OK29N5&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 108.177.127.132, 2a00:1450:4013:c07::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|108.177.127.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-08-26 16:37:56 ERROR 404: Not Found.\n",
            "\n",
            "\n",
            "Verificando o tipo do arquivo baixado...\n",
            "/content/dataset.zip: empty\n",
            "\n",
            "Descompactando o dataset para '/mydrive/FaceMaskDataset'...\n",
            "[/content/dataset.zip]\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/dataset.zip or\n",
            "        /content/dataset.zip.zip, and cannot find /content/dataset.zip.ZIP, period.\n",
            "\n",
            "ERRO CRÍTICO: A descompactação falhou ou o dataset não contém os arquivos esperados.\n",
            "O arquivo '/mydrive/FaceMaskDataset/train/_darknet.txt' não foi encontrado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ETAPA 4: Configuração do Arquivo .cfg do Modelo ---\n",
        "%cd /content/darknet\n",
        "\n",
        "print(\"Configurando o arquivo yolov3_custom.cfg...\")\n",
        "# Copia o arquivo de configuração padrão\n",
        "!cp cfg/yolov3.cfg /mydrive/yolov3_custom.cfg\n",
        "\n",
        "# Altera o arquivo para 2 classes e ajusta parâmetros de treino\n",
        "!sed -i 's/batch=64/batch=64/' /mydrive/yolov3_custom.cfg\n",
        "!sed -i 's/subdivisions=16/subdivisions=16/' /mydrive/yolov3_custom.cfg\n",
        "!sed -i 's/max_batches = 500200/max_batches = 4000/' /mydrive/yolov3_custom.cfg\n",
        "!sed -i 's/steps=400000,450000/steps=3200,3600/' /mydrive/yolov3_custom.cfg\n",
        "!sed -i 's/classes=80/classes=2/g' /mydrive/yolov3_custom.cfg\n",
        "# A fórmula para os filtros é (classes + 5) * 3 = (2 + 5) * 3 = 21\n",
        "!sed -i 's/filters=255/filters=21/g' /mydrive/yolov3_custom.cfg\n",
        "\n",
        "print(\"Arquivo yolov3_custom.cfg configurado com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfSmAeF2JImL",
        "outputId": "3ae9803b-add2-48b6-b357-cbb7472a6bba"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/darknet\n",
            "Configurando o arquivo yolov3_custom.cfg...\n",
            "Arquivo yolov3_custom.cfg configurado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ETAPA 5: Treinamento ---\n",
        "%cd /content/darknet\n",
        "\n",
        "# 1. Baixa os pesos convolucionais pré-treinados (para transfer learning)\n",
        "if not os.path.exists('darknet53.conv.74'):\n",
        "    !wget https://pjreddie.com/media/files/darknet53.conv.74\n",
        "\n",
        "# 2. Inicia o treinamento\n",
        "print(\"\\nINICIANDO O TREINAMENTO...\")\n",
        "!./darknet detector train /mydrive/obj.data /mydrive/yolov3_custom.cfg darknet53.conv.74 -dont_show -map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZaQZ1HhJUjL",
        "outputId": "0c3b7f2c-9d67-4e11-e7ab-07d2652edc0b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/darknet\n",
            "--2025-08-26 16:32:25--  https://pjreddie.com/media/files/darknet53.conv.74\n",
            "Resolving pjreddie.com (pjreddie.com)... 172.67.185.199, 104.21.88.156, 2606:4700:3037::6815:589c, ...\n",
            "Connecting to pjreddie.com (pjreddie.com)|172.67.185.199|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘darknet53.conv.74’\n",
            "\n",
            "darknet53.conv.74       [ <=>                ]   8.88K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-08-26 16:32:26 (97.3 MB/s) - ‘darknet53.conv.74’ saved [9093]\n",
            "\n",
            "\n",
            "INICIANDO O TREINAMENTO...\n",
            "/bin/bash: line 1: ./darknet: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ETAPA 6: Teste do Modelo Treinado ---\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Função para exibir imagens no Colab\n",
        "def imShow(path):\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"ERRO: O arquivo de imagem de resultado '{path}' não foi encontrado.\")\n",
        "        print(\"Isso geralmente significa que o comando de detecção falhou.\")\n",
        "        return\n",
        "    image = cv2.imread(path)\n",
        "    if image is None:\n",
        "        print(f\"ERRO: O OpenCV não conseguiu ler o arquivo de resultado '{path}'.\")\n",
        "        return\n",
        "    height, width = image.shape[:2]\n",
        "    resized_image = cv2.resize(image, (3*width, 3*height), interpolation=cv2.INTER_CUBIC)\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(18, 10)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "\n",
        "# Garante que estamos no diretório correto para executar o darknet\n",
        "%cd /content/darknet\n",
        "\n",
        "# Recria a lista de arquivos de teste para garantir que a variável exista\n",
        "all_images = glob.glob(\"/mydrive/Face-Mask-Detection/images/*.png\") + glob.glob(\"/mydrive/Face-Mask-Detection/images/*.jpg\")\n",
        "test_files = all_images[int(len(all_images)*0.8):]\n",
        "\n",
        "if not test_files:\n",
        "    print(\"ERRO: Nenhum arquivo de teste encontrado. Execute a célula de preparação do dataset primeiro.\")\n",
        "else:\n",
        "    # --- PONTO DE CONFIGURAÇÃO PRINCIPAL ---\n",
        "    # Verifique na sua pasta /mydrive/backup/ o nome do arquivo de pesos que deseja testar\n",
        "    weights_path = \"/mydrive/backup/yolov3_custom_last.weights\"\n",
        "\n",
        "    # Seleciona a primeira imagem da lista de teste. Mude o índice para testar outras (ex: test_files[1])\n",
        "    image_path_to_test = test_files[0]\n",
        "\n",
        "    print(f\"Usando os pesos: {weights_path}\")\n",
        "    print(f\"Testando na imagem: {image_path_to_test}\")\n",
        "\n",
        "    # Verifica se o arquivo de pesos realmente existe\n",
        "    if not os.path.exists(weights_path):\n",
        "        print(f\"\\nERRO CRÍTICO: O arquivo de pesos '{weights_path}' não foi encontrado!\")\n",
        "        print(\"Verifique o nome do arquivo na sua pasta '/mydrive/backup/' e corrija a variável 'weights_path'.\")\n",
        "    else:\n",
        "        # Roda o comando de detecção\n",
        "        !./darknet detector test /mydrive/obj.data /mydrive/yolov3_custom.cfg {weights_path} {image_path_to_test} -thresh 0.3\n",
        "\n",
        "        # Exibe o resultado, que é salvo como 'predictions.jpg'\n",
        "        print(\"\\n--- Resultado da Detecção ---\")\n",
        "        imShow('predictions.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKcZUELHOklc",
        "outputId": "d85256ca-da64-4330-f5ab-1797de607fd2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/darknet\n",
            "ERRO: Nenhum arquivo de teste encontrado. Execute a célula de preparação do dataset primeiro.\n"
          ]
        }
      ]
    }
  ]
}